{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avIncomePerUser = 400 #сколько денег в среднем приносит один пользователь в месяц;\n",
    "avSparePerUser = 100 #сколько денег в среднем вы будете вкладывать в удержание одного пользователя;\n",
    "probAccept = 0.7 #с какой вероятностью пользователь примет ваше предложение;\n",
    "topPercentToHold = 10 #сколько пользователей (например, топ 1% или топ 25% согласно ранжированию по вашей модели) будет участвовать в кампании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#будем рассчитывать доход от проведения удержания по каждому поьзователю (profitPerUser) так(он может быть отрицательным):\n",
    "# incomePerUserNoAction = avIncomePerUser * (1-probChurn)\n",
    "# incomePerUserAction = avIncomePerUser * probAccept - avSparePerUser\n",
    "# profitPerUser = incomePerUserAction - incomePerUserNoAction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20253190381202768"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#нужно найти вероятность ухода каждого пользователя, которого собираемся удерживать, обратимся для этого к модели\n",
    "#cначала загрузим данные и подготовим модель с прошлой недели\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "data_all.shape\n",
    "\n",
    "#выполняем на ней ту же обработку, что для набора обучения\n",
    "test_num = test.iloc[:, 0:numericalVarCount]\n",
    "#выкинем признаки, которые выкидывали при обучении\n",
    "test_num = test.loc[:,numVarsToStay]\n",
    "#заполним NaN медианными значениями train!!! набора\n",
    "test_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию, с теми же параметрами, что при обучении:\n",
    "test_num = scaler.transform(test_num)\n",
    "test_cat = test.iloc[:, numericalVarCount:-1]\n",
    "test_cat = test_cat.loc[:,catVarsToStay]\n",
    "test_cat = test_cat.fillna('NA').astype(str)\n",
    "test_cat_oh = encoder.transform(test_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "test_all = np.hstack((test_num,test_cat_oh))\n",
    "\n",
    "\n",
    "#будем использовать следующие модели для baseline решения:\n",
    "#RandomForestClassifier, RidgeClassifier и SGDClassifier\n",
    "#ввиду несбалансированности выборок везде используем class_weight='balanced'\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all, target)\n",
    "scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "basic_score = scores.mean()\n",
    "basic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35513105,  0.19989424,  0.41336346, ...,  0.74328987,\n",
       "        0.33162091,  0.5486033 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#для всех оценок будем использовать тестовую выборку\n",
    "probs = clf.predict_proba(test_all)[:,1]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#соритируем вероятности по убыванию\n",
    "probs[::-1].sort()\n",
    "#и берем определенный процент пользователей, которых собираемся удерживать\n",
    "probs = probs[:round(probs.shape[0] * topPercentToHold/100.0)]\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посчитаем с заданными параметрами доход от проведения кампании по удержанию:\n",
    "probChurn = probs\n",
    "incomePerUserNoAction = avIncomePerUser * (1-probChurn)\n",
    "incomePerUserAction = avIncomePerUser * probAccept - avSparePerUser\n",
    "profitPerUser = incomePerUserAction - incomePerUserNoAction;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1: Итоговая прибыль по проведению кампании по удержанию, если использовать параметры из начала ноутбука:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48949.661171431086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(profitPerUser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2: Для ответа на вопрос, посмотрим, начиная с какого процента пользователей, начнутся убытки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36733333333333335"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#применим те же рассчеты, что и ранее, только изменим процент пользователей\n",
    "topPercentToHold = 100\n",
    "probs = clf.predict_proba(test_all)[:,1]\n",
    "probs[::-1].sort()\n",
    "probs = probs[:round(probs.shape[0] * topPercentToHold/100.0)]\n",
    "probChurn = probs\n",
    "incomePerUserNoAction = avIncomePerUser * (1-probChurn)\n",
    "incomePerUserAction = avIncomePerUser * probAccept - avSparePerUser\n",
    "profitPerUser = incomePerUserAction - incomePerUserNoAction;\n",
    "percent = np.sum(profitPerUser > 0)/profitPerUser.shape[0]\n",
    "percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, экономически выгодно проводить компанию по топ-37 процентам пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3: Добавим еще параметры: непредвиденные расходы, вероятность их возникновения, непредвиденные доходы и их вероятность\n",
    "также изменим стоимость удержания и вероятность принятия пользователем предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avSparePerUser = 300 #сколько денег в среднем вы будете вкладывать в удержание одного пользователя;\n",
    "probAccept = 0.5 #с какой вероятностью пользователь примет ваше предложение;\n",
    "UnexpectedIncomeProb = 0.6 #вероятность непредвиденной прибыли на пользователя\n",
    "UnexpectedSpareProb = 0.5 #вероятность непредвиденных расходов на пользователя\n",
    "UnexpectedIncome = 50 #размер непредвиденной прибыли на пользователя\n",
    "UnexpectedSpare = 60 #размер непредвиденных расходов на пользователя\n",
    "\n",
    "WeightedUnexpectedIncome = UnexpectedIncome * UnexpectedIncomeProb\n",
    "WeightedUnexpectedSpare = UnexpectedSpare * UnexpectedSpareProb\n",
    "\n",
    "topPercentToHold = 100\n",
    "probs = clf.predict_proba(test_all)[:,1]\n",
    "probs[::-1].sort()\n",
    "probs = probs[:round(probs.shape[0] * topPercentToHold/100.0)]\n",
    "probChurn = probs\n",
    "incomePerUserNoAction = avIncomePerUser * (1-probChurn)\n",
    "incomePerUserAction = avIncomePerUser * probAccept - avSparePerUser + WeightedUnexpectedIncome - WeightedUnexpectedSpare\n",
    "profitPerUser = incomePerUserAction - incomePerUserNoAction;\n",
    "percent = np.sum(profitPerUser > 0)/profitPerUser.shape[0]\n",
    "percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что из-за увеличения стоимости удержания и уменьшения вероятности принятия предложения, кампанию стало проводить невыгодно: процент пользователей, с которых можно получить пользу от проведения компании теперь равен 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4: Применение модели выгодно не всегда, например, параметры, при которых невыгодно проводить кампанию:\n",
    "\n",
    "avSparePerUser = 300 #сколько денег в среднем вы будете вкладывать в удержание одного пользователя;\n",
    "\n",
    "probAccept = 0.5 #с какой вероятностью пользователь примет ваше предложение;\n",
    "\n",
    "UnexpectedIncomeProb = 0.6 #вероятность непредвиденной прибыли на пользователя\n",
    "\n",
    "UnexpectedSpareProb = 0.5 #вероятность непредвиденных расходов на пользователя\n",
    "\n",
    "UnexpectedIncome = 50 #размер непредвиденной прибыли на пользователя\n",
    "\n",
    "UnexpectedSpare = 60 #размер непредвиденных расходов на пользователя\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5: После проведения тестирования, выяснилось, что при улучшении качества модели (по метрике f1_score) и фиксированных\n",
    "остальных параметрах на 1% и 3% можно добиться увеличения прибыли на 0.5835% и 0.9436% соответственно по сравнению с прибылью из пункта 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6: Ответ на вопрос зависит от параметров экономической модели. Если использовать параметры, как в задании 1, то вложение\n",
    "средств является экономически оправданным, но, как видно из результатов в задании 4, чтобы существенно повысить прибыль, при использовании модели, нужно очень сильно повысить качество предсказываемых вероятностей оттока, что не представляется возможным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
