{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":177,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/orange_small_churn_data.csv', delimiter =',')\ndata['labels'] = pd.read_csv('../input/orange_small_churn_labels.csv', header=None)\n#конвертируем колонку labels в int\ndata = data.astype({'labels': 'int32'})\n#заменим все -1 в целевой переменной на 0\ndata['labels'] = data['labels'].map({1: 1, -1: 0})","execution_count":178,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndata, holdOut = train_test_split(data, test_size=0.15, random_state=42)","execution_count":179,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#на этой выборке будем обучать модели. переменная holdOut - это hold out, ее мы не будем использовать ни для обучения \n#ни для оценки baseline моделей\ndata.shape","execution_count":180,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#отделим столбец с целевой переменной\ntarget = np.array(data.iloc[:,-1])\ntarget.shape","execution_count":181,"outputs":[{"output_type":"execute_result","execution_count":181,"data":{"text/plain":"(34000,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#подготовим даные:\n#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\nnumericalVarCount = 190\ncategorialVarCount = 40\n\ndata_num = data.iloc[:, 0:numericalVarCount]\n#удалим числовые признаки, содержащие слишком большое количество NaN - значений\nthreshold = 0.7\nNaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\nnumVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\ndata_num = data_num.loc[:,numVarsToStay]\n#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\nmedians = data_num.median()\ndata_num.fillna(medians, inplace=True)\n#выполним стандартизацию числовых признаков\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndata_num = scaler.fit_transform(data_num)\ndata_num.shape\n","execution_count":182,"outputs":[{"output_type":"execute_result","execution_count":182,"data":{"text/plain":"(34000, 42)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# #обработаем категориальные признаки методикой one-hot-encoding\nfrom sklearn.feature_extraction import DictVectorizer as DV\ndata_cat = data.iloc[:, numericalVarCount:-1]\n\ndata_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\nNaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\nNaN_frac\nthreshold = 0.1\nNaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\ncatVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\ndata_cat = data_cat.loc[:,catVarsToStay]\ndata_cat = data_cat.fillna('NA').astype(str)\n\n#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\nunique_counts = []\nfor c in data_cat.columns:\n    unique_counts.append(data_cat[c].dropna().unique().shape[0])\ncat_unique = pd.DataFrame()\ncat_unique['unique_counts'] = unique_counts\ncat_unique.index = data_cat.columns\ncat_unique.sort_values(by='unique_counts', ascending=False)\ncat_unique\n","execution_count":183,"outputs":[{"output_type":"execute_result","execution_count":183,"data":{"text/plain":"        unique_counts\nVar192            347\nVar193             47\nVar195             22\nVar196              4\nVar197            220\nVar198           3587\nVar199           3929\nVar202           5385\nVar203              6\nVar204            100\nVar205              4\nVar207             14\nVar208              3\nVar210              6\nVar211              2\nVar212             77\nVar216           1676\nVar217          11379\nVar218              3\nVar220           3587\nVar221              7\nVar222           3587\nVar226             23\nVar227              7\nVar228             30","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Var192</th>\n      <td>347</td>\n    </tr>\n    <tr>\n      <th>Var193</th>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>Var195</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>Var196</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Var197</th>\n      <td>220</td>\n    </tr>\n    <tr>\n      <th>Var198</th>\n      <td>3587</td>\n    </tr>\n    <tr>\n      <th>Var199</th>\n      <td>3929</td>\n    </tr>\n    <tr>\n      <th>Var202</th>\n      <td>5385</td>\n    </tr>\n    <tr>\n      <th>Var203</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Var204</th>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>Var205</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Var207</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>Var208</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Var210</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Var211</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Var212</th>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>Var216</th>\n      <td>1676</td>\n    </tr>\n    <tr>\n      <th>Var217</th>\n      <td>11379</td>\n    </tr>\n    <tr>\n      <th>Var218</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Var220</th>\n      <td>3587</td>\n    </tr>\n    <tr>\n      <th>Var221</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>Var222</th>\n      <td>3587</td>\n    </tr>\n    <tr>\n      <th>Var226</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>Var227</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>Var228</th>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\ncat_feat_for_OHE\nencoder = DV(sparse = False)\ndata_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())","execution_count":184,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat_oh.shape","execution_count":185,"outputs":[{"output_type":"execute_result","execution_count":185,"data":{"text/plain":"(34000, 178)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isna(data_cat_oh).sum().sum()","execution_count":186,"outputs":[{"output_type":"execute_result","execution_count":186,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#объединяем обработанные числовые и категориальные признаки\ndata_all = np.hstack((data_num,data_cat_oh))\ndata_all.shape","execution_count":187,"outputs":[{"output_type":"execute_result","execution_count":187,"data":{"text/plain":"(34000, 220)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#будем использовать следующие модели для baseline решения:\n#RandomForestClassifier, RidgeClassifier и SGDClassifier\n#ввиду несбалансированности выборок везде используем class_weight='balanced'\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\n#from sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression","execution_count":190,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nclf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n# scores = cross_val_score(clf, data_all, target, cv=5, scoring = 'f1')\n# scores.mean()\n\n# clf = LogisticRegression(class_weight='balanced', penalty='l1')\n# scores = cross_val_score(clf, data_all, target, cv=5, scoring = 'f1')\n# scores.mean()\n\n\n# from sklearn.neural_network import MLPClassifier\n# clf = MLPClassifier(hidden_layer_sizes=(128,64,32,16,8),learning_rate_init = 0.01, max_iter = 500)\n# scores = cross_val_score(clf, data_num, target, cv=5, scoring = 'f1')\n# scores.mean()\n\n# from sklearn.ensemble import GradientBoostingClassifier\n# clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1, max_depth=11, random_state=0)\n# scores = cross_val_score(clf, data_num, target, cv=5, scoring = 'f1')\n# scores.mean()\n# clf = SVC(gamma='auto',kernel = 'linear')\n# scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n\n# clf = LinearSVC(class_weight = 'balanced', random_state = 42)\n# scores = cross_val_score(clf, data_all, target, cv=5, scoring = 'roc_auc')\n# scores.mean()\n\n# clf = RandomForestClassifier(n_estimators=100, max_depth=4, class_weight ='balanced', random_state=42)\n# scores = cross_val_score(clf, data_num, target, cv=3, scoring = 'roc_auc')\n# scores.mean()\n# import xgboost as xgb\n# clf = xgb.XGBClassifier()\n# scores = cross_val_score(gbm, data_all, target, cv=3, scoring = 'f1')\n# scores","execution_count":191,"outputs":[{"output_type":"execute_result","execution_count":191,"data":{"text/plain":"0.2016434155048039"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import xgboost as xgb\n# clf = xgb.XGBClassifier()\n# scores = cross_val_score(clf, data_num, target, cv=3, scoring = 'roc_auc')\n# scores.mean()","execution_count":192,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#загружаем тестовую выборку:\ntest = pd.read_csv('../input/orange_small_churn_test_data.csv',delimiter = ',')\ntest.drop(columns = 'ID', inplace=True)\ntest.head()","execution_count":193,"outputs":[{"output_type":"execute_result","execution_count":193,"data":{"text/plain":"   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  Var221  \\\n0   NaN   NaN   NaN   NaN   NaN  1225.0   7.0   NaN   NaN    NaN  ...    zCkv   \n1   NaN   NaN   NaN   NaN   NaN   896.0  14.0   NaN   NaN    NaN  ...    oslk   \n2   NaN   NaN   NaN   NaN   NaN   791.0   7.0   NaN   NaN    NaN  ...    oslk   \n3   NaN   NaN   NaN   NaN   NaN  2296.0   7.0   NaN   NaN    NaN  ...    oslk   \n4   8.0   NaN   NaN   NaN   NaN     NaN   NaN   NaN  28.0    NaN  ...    oslk   \n\n    Var222      Var223  Var224  Var225  Var226  Var227         Var228  Var229  \\\n0  APgdzOv  jySVZNlOJy     NaN    ELof    xb3V    6fzt        Zy3gnGM     NaN   \n1  IIvC99a  LM8l689qOp     NaN     NaN    xb3V    RAYp  F2FyR07IdsN7I     NaN   \n2  6YSocsg  LM8l689qOp     NaN    kG3k    rgKb    RAYp  F2FyR07IdsN7I    mj86   \n3  5nQ7A2G  jySVZNlOJy     NaN    kG3k    rgKb    RAYp  F2FyR07IdsN7I    am7c   \n4  MI8s5nE  LM8l689qOp     NaN     NaN    7P5s    RAYp  F2FyR07IdsN7I     NaN   \n\n   Var230  \n0     NaN  \n1     NaN  \n2     NaN  \n3     NaN  \n4     NaN  \n\n[5 rows x 230 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Var1</th>\n      <th>Var2</th>\n      <th>Var3</th>\n      <th>Var4</th>\n      <th>Var5</th>\n      <th>Var6</th>\n      <th>Var7</th>\n      <th>Var8</th>\n      <th>Var9</th>\n      <th>Var10</th>\n      <th>...</th>\n      <th>Var221</th>\n      <th>Var222</th>\n      <th>Var223</th>\n      <th>Var224</th>\n      <th>Var225</th>\n      <th>Var226</th>\n      <th>Var227</th>\n      <th>Var228</th>\n      <th>Var229</th>\n      <th>Var230</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1225.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>zCkv</td>\n      <td>APgdzOv</td>\n      <td>jySVZNlOJy</td>\n      <td>NaN</td>\n      <td>ELof</td>\n      <td>xb3V</td>\n      <td>6fzt</td>\n      <td>Zy3gnGM</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>896.0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>oslk</td>\n      <td>IIvC99a</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xb3V</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>791.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>oslk</td>\n      <td>6YSocsg</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>kG3k</td>\n      <td>rgKb</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>mj86</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2296.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>oslk</td>\n      <td>5nQ7A2G</td>\n      <td>jySVZNlOJy</td>\n      <td>NaN</td>\n      <td>kG3k</td>\n      <td>rgKb</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>am7c</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>oslk</td>\n      <td>MI8s5nE</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7P5s</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 230 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#выполняем на ней ту же обработку, что для набора обучения\ntest_num = test.iloc[:, 0:numericalVarCount]\n#выкинем признаки, которые выкидывали при обучении\ntest_num = test.loc[:,numVarsToStay]\n#заполним NaN медианными значениями train!!! набора\ntest_num.fillna(medians, inplace=True)\n#выполним стандартизацию, с теми же параметрами, что при обучении:\ntest_num = scaler.transform(test_num)\ntest_cat = test.iloc[:, numericalVarCount:-1]\ntest_cat = test_cat.loc[:,catVarsToStay]\ntest_cat = test_cat.fillna('NA').astype(str)\ntest_cat_oh = encoder.transform(test_cat[cat_feat_for_OHE].T.to_dict().values())\ntest_all = np.hstack((test_num,test_cat_oh))\ntest_all.shape","execution_count":194,"outputs":[{"output_type":"execute_result","execution_count":194,"data":{"text/plain":"(10000, 220)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.1)\nclf.fit(data_all, target)\n\n# clf = xgb.XGBClassifier(scale_pos_weight=0.90)\n# clf.fit(data_num, target)","execution_count":196,"outputs":[{"output_type":"execute_result","execution_count":196,"data":{"text/plain":"SGDClassifier(alpha=0.01, average=False, class_weight='balanced',\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n              random_state=42, shuffle=True, tol=0.0001,\n              validation_fraction=0.1, verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testPredictions = clf.predict(test_num)\ntestPredictions = clf.predict_proba(test_all)[:,1]","execution_count":197,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#записываем ответ в файл\nansData = {'Id':test.index, 'result':testPredictions} \nans = pd.DataFrame(ansData)\nans.to_csv('ans.csv', index= False)","execution_count":198,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}