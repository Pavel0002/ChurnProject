{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cначала загрузим данные и подготовим модель с прошлой недели\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "data_all.shape\n",
    "\n",
    "#выполняем на ней ту же обработку, что для набора обучения\n",
    "test_num = test.iloc[:, 0:numericalVarCount]\n",
    "#выкинем признаки, которые выкидывали при обучении\n",
    "test_num = test.loc[:,numVarsToStay]\n",
    "#заполним NaN медианными значениями train!!! набора\n",
    "test_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию, с теми же параметрами, что при обучении:\n",
    "test_num = scaler.transform(test_num)\n",
    "test_cat = test.iloc[:, numericalVarCount:-1]\n",
    "test_cat = test_cat.loc[:,catVarsToStay]\n",
    "test_cat = test_cat.fillna('NA').astype(str)\n",
    "test_cat_oh = encoder.transform(test_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "test_all = np.hstack((test_num,test_cat_oh))\n",
    "\n",
    "\n",
    "#будем использовать следующие модели для baseline решения:\n",
    "#RandomForestClassifier, RidgeClassifier и SGDClassifier\n",
    "#ввиду несбалансированности выборок везде используем class_weight='balanced'\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "\n",
    "scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "basic_score = scores.mean()\n",
    "\n",
    "# clf.fit(data_all, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#используем подготовленные данные и модель для построения кривых обучения\n",
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes=np.linspace(.1, 1.0, 5)\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, data_all, target,train_sizes=train_sizes, n_jobs=1, cv= None,scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26900179,  0.20142836,  0.20030722,  0.19814001,  0.20743172])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18030355,  0.18540377,  0.19096725,  0.19257354,  0.19898689])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e852dd8>]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1be1b0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: похоже, если добавить еще данных при обучении, можно улучшить результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в моделе с прошлой недели уже были использованны веса (параметр class_weight='balanced)\n",
    "#таким образом, один из способов учета весов уже применен, осталось применить еще 2\n",
    "# scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "# score_modelWeights = scores.mean()\n",
    "from sklearn.metrics import f1_score\n",
    "clf.fit(data_all, target)\n",
    "test_pred = clf.predict(test_all)\n",
    "score_modelWeights = f1_score(target_test, test_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Веса вручную\n",
    "#т.к. в наших данных клиентов склонных к оттоку грубо 10% размножим их данные, чтобы сбалансировать классы\n",
    "dataChunr = data_all[target == 1,:]\n",
    "target = target[:,np.newaxis]\n",
    "targetChurn = target[target == 1]\n",
    "targetChurn = targetChurn[:,np.newaxis]\n",
    "data_all_ForHand = data_all\n",
    "target_ForHand = target\n",
    "for i in range(10):\n",
    "    data_all_ForHand =  np.vstack((data_all_ForHand,dataChunr))\n",
    "    target_ForHand = np.vstack((target_ForHand,targetChurn))\n",
    "target_ForHand = target_ForHand.ravel()\n",
    "target = target.ravel()\n",
    "# scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "# score_HandWeights = scores.mean()\n",
    "clf = SGDClassifier(loss = 'log', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all_ForHand, target_ForHand)\n",
    "test_pred = clf.predict(test_all)\n",
    "score_HandWeights = f1_score(target_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Комбинированные веса: когда мы выполняли веса \"вручную\" мы ПРИМЕРНО сбалансировали выборку,\n",
    "#поэтому, чтобы сделать веса точнее попробуем оба подхода одновременно\n",
    "clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all_ForHand, target_ForHand)\n",
    "test_pred = clf.predict(test_all)\n",
    "score_HandWeightsAndModelWeights = f1_score(target_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20212443095599394, 0.21720969089390138, 0.21386603995299647)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сравним оценки моделей с разными весами\n",
    "score_modelWeights, score_HandWeights, score_HandWeightsAndModelWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Использование различных методов задания весов влияет на результат незначительно, но любой способ дает лучший результат,\n",
    "чем без использования весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.202907915993538, 0.20754716981132074, 0.090909090909090912)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#undersampling до равного отношения числа классов\n",
    "data_Churn = data_all[target == 1,:]\n",
    "target_Churn = target[target == 1]\n",
    "data_notChurn = data_all[target == 0,:][:data_Churn.shape[0],:]\n",
    "target_notChurn = target[target == 0][:data_Churn.shape[0]]\n",
    "data_all_undersampled = np.vstack((data_Churn, data_notChurn))\n",
    "target_undersampled = np.vstack((target_Churn[:,np.newaxis], target_notChurn[:,np.newaxis])).ravel()\n",
    "\n",
    "clf = SGDClassifier(loss = 'log', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all_undersampled, target_undersampled)\n",
    "test_pred = clf.predict(test_all)\n",
    "score_undersampled1 = f1_score(target_test, test_pred)\n",
    "\n",
    "#undersampling до отношения числа классов 1:2\n",
    "\n",
    "data_notChurn = data_all[target == 0,:][:data_Churn.shape[0]*2,:]\n",
    "target_notChurn = target[target == 0][:data_Churn.shape[0]*2]\n",
    "data_all_undersampled = np.vstack((data_Churn, data_notChurn))\n",
    "target_undersampled = np.vstack((target_Churn[:,np.newaxis], target_notChurn[:,np.newaxis])).ravel()\n",
    "\n",
    "clf = SGDClassifier(loss = 'log', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all_undersampled, target_undersampled)\n",
    "test_pred = clf.predict(test_all)\n",
    "score_undersampled2 = f1_score(target_test, test_pred)\n",
    "\n",
    "#undersampling до отношения числа классов 1:3\n",
    "\n",
    "data_notChurn = data_all[target == 0,:][:data_Churn.shape[0]*3,:]\n",
    "target_notChurn = target[target == 0][:data_Churn.shape[0]*3]\n",
    "data_all_undersampled = np.vstack((data_Churn, data_notChurn))\n",
    "target_undersampled = np.vstack((target_Churn[:,np.newaxis], target_notChurn[:,np.newaxis])).ravel()\n",
    "\n",
    "clf = SGDClassifier(loss = 'log', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all_undersampled, target_undersampled)\n",
    "test_pred = clf.predict(test_all)\n",
    "score_undersampled3 = f1_score(target_test, test_pred)\n",
    "\n",
    "#результаты с разным undersampling'ом\n",
    "score_undersampled1, score_undersampled2, score_undersampled3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вывод: undersampling нужно обязательно делать таким образом, чтобы классы стали сбалансированны,\n",
    "иначе улучшения результата не наблюдается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20253190381202768, 0.19818173806276984)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#В исходной модели пропуски числовых переменных заменялись на медианные значения, попробуем теперь заменять на 0:\n",
    "\n",
    "#cначала загрузим данные и подготовим модель с прошлой недели\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "data_num.fillna(0, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "\n",
    "clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "\n",
    "scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "with_zeros_score = scores.mean()\n",
    "basic_score, with_zeros_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: замена пропущенных числовых значений на 0 дает примерно такое же качество модели, как и замена на медианное значение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20253190381202768, 0.19176117617552371)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#в решении с прошлой недели обрабатывались только категориальные признаки с количеством категорий меньше 50 при помощи\n",
    "# one-hot-encoding сравним качество модели, если обрабатывать только признаки с количеством категорий меньше 5\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 5].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "\n",
    "scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "cat5_score = scores.mean()\n",
    "basic_score, cat5_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вывод: обработка категориальных признаком с количеством категорий до 50 дает немного лучший результат по сравнению с обработкой\n",
    "категорий с 5 различными признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "data_all.shape\n",
    "\n",
    "#выполняем на ней ту же обработку, что для набора обучения\n",
    "test_num = test.iloc[:, 0:numericalVarCount]\n",
    "#выкинем признаки, которые выкидывали при обучении\n",
    "test_num = test.loc[:,numVarsToStay]\n",
    "#заполним NaN медианными значениями train!!! набора\n",
    "test_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию, с теми же параметрами, что при обучении:\n",
    "test_num = scaler.transform(test_num)\n",
    "test_cat = test.iloc[:, numericalVarCount:-1]\n",
    "test_cat = test_cat.loc[:,catVarsToStay]\n",
    "test_cat = test_cat.fillna('NA').astype(str)\n",
    "test_cat_oh = encoder.transform(test_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "test_all = np.hstack((test_num,test_cat_oh))\n",
    "\n",
    "#балансировка вручную\n",
    "dataChunr = data_all[target == 1,:]\n",
    "target = target[:,np.newaxis]\n",
    "targetChurn = target[target == 1]\n",
    "targetChurn = targetChurn[:,np.newaxis]\n",
    "data_all_ForHand = data_all\n",
    "target_ForHand = target\n",
    "for i in range(10):\n",
    "    data_all_ForHand =  np.vstack((data_all_ForHand,dataChunr))\n",
    "    target_ForHand = np.vstack((target_ForHand,targetChurn))\n",
    "target_ForHand = target_ForHand.ravel()\n",
    "target = target.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2153846153846154"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим Lasso\n",
    "clf = Lasso(alpha = 0.000001)\n",
    "clf.fit(data_all_ForHand, target_ForHand)\n",
    "test_pred = clf.predict(test_all)\n",
    "#проверим адекватность обученной модели\n",
    "test_pred = np.round(test_pred)\n",
    "score_lasso = f1_score(target_test, test_pred)\n",
    "score_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.79139946e-03,  -2.75350735e-02,  -3.34922692e-03,\n",
       "        -1.57486899e-01,   8.63319596e-02,  -2.57572909e-04,\n",
       "         1.59359739e-02,   5.51169525e-03,   3.89264516e-03,\n",
       "         2.69105481e-02,  -3.99235678e-03,   1.62955533e-03,\n",
       "         1.55065249e-02,  -1.20501425e-02,  -7.33790306e-02,\n",
       "        -1.35834241e-02,   1.32448359e-02,   8.25602956e-03,\n",
       "         1.24473197e-02,   1.56137341e-02,  -9.63582373e-03,\n",
       "        -4.50317591e-03,  -8.01241840e-03,   3.19055078e-02,\n",
       "         4.05440776e-02,   5.58696084e-03,   2.92892604e-02,\n",
       "        -2.66055762e-03,   6.42722325e-02,   3.11107155e-03,\n",
       "         1.42946859e-02,   2.07935789e-02,   1.13941746e-04,\n",
       "         6.41286052e-03,   1.42774083e-02,   1.66801737e-03,\n",
       "        -6.03579945e-02,   3.70412922e-03,   4.81611676e-03,\n",
       "         1.15578596e-03,  -9.13106393e-04,  -5.37344792e-02,\n",
       "         6.71603693e-02,   0.00000000e+00,  -3.65284123e-02,\n",
       "        -1.10479775e-01,  -4.73472226e-02,  -1.11962797e-02,\n",
       "        -9.62652635e-02,   4.36090570e-01,  -6.52846871e-02,\n",
       "        -1.99460984e-01,   3.88226632e-01,  -2.38531115e-01,\n",
       "         5.04119677e-01,  -2.12811526e-01,  -3.68119982e-01,\n",
       "        -3.84837826e-02,   1.27369544e-02,  -7.96571142e-02,\n",
       "        -1.22597299e-02,  -1.58580402e-01,  -1.21931655e-01,\n",
       "        -0.00000000e+00,   9.16712201e-02,   7.24326549e-02,\n",
       "        -4.39378711e-02,   3.44406834e-01,  -1.31531435e-01,\n",
       "         7.33256682e-02,   1.61871515e-02,   1.41898106e-04,\n",
       "         1.30575519e-01,   1.06362744e-01,  -1.71608216e-01,\n",
       "        -9.80120107e-02,  -1.87389188e-01,  -9.31134487e-03,\n",
       "        -6.96836110e-03,   1.80122027e-01,   1.02837471e-01,\n",
       "        -1.06291544e-01,   6.96380365e-02,  -6.73160873e-02,\n",
       "         1.36416230e-01,   0.00000000e+00,   1.27347945e-01,\n",
       "         0.00000000e+00,  -3.63615079e-01,  -3.31703315e-01,\n",
       "         7.54444763e-01,  -5.02637460e-01,  -3.34147511e-01,\n",
       "        -1.88784650e-02,   1.11641935e+00,   1.49359985e-01,\n",
       "        -3.84578899e-01,  -1.81313922e-01,  -5.91277106e-02,\n",
       "         4.73392834e-02,   4.77693903e-02,   1.73426689e-01,\n",
       "        -2.12751709e-03,   1.22647061e-02,  -3.48356409e-01,\n",
       "         7.85386193e-02,  -3.48887152e-01,  -1.08638092e-01,\n",
       "        -9.34594953e-02,   1.57175826e-01,   1.00454423e-01,\n",
       "         2.14042666e-05,  -4.85354775e-02,  -1.17259200e-02,\n",
       "         4.05897114e-02,  -1.05271441e-02,   1.02841297e-02,\n",
       "         2.35365076e-02,  -5.99392070e-02,  -3.58878132e-01,\n",
       "        -0.00000000e+00,  -4.65317719e-02,   8.44302226e-03,\n",
       "        -4.12711508e-02,   6.28994657e-02,   2.34979395e-01,\n",
       "         2.83220986e-03,   3.30068195e-01,   1.23822564e-01,\n",
       "         4.58736973e-02,  -4.01199319e-02,  -3.88193374e-01,\n",
       "        -1.22194907e-02,   2.34393671e-01,   3.32085557e-01,\n",
       "        -6.67672428e-03,  -4.23976070e-01,  -3.23130550e-01,\n",
       "        -4.65008073e-01,  -8.61727296e-03,  -3.79643568e-03,\n",
       "         1.33649304e-02,  -2.96978834e-01,  -2.17237851e-02,\n",
       "         1.17967180e-01,   3.47254629e-01,   1.98839213e-01,\n",
       "        -4.64348269e-03,   2.61651841e-02,  -0.00000000e+00,\n",
       "         3.54776889e-01,   6.20903225e-02,  -7.81683129e-03,\n",
       "         1.35146351e-01,  -3.15960617e-02,  -6.88753641e-03,\n",
       "        -9.67901059e-02,   2.33751035e-03,   7.24812814e-02,\n",
       "         0.00000000e+00,   1.72789133e-02,   1.74615810e-02,\n",
       "         2.47979417e-02,   5.05151317e-02,  -5.40151259e-02,\n",
       "        -3.14532629e-02,  -7.89987964e-03,   4.61295776e-02,\n",
       "         3.98749124e-02,  -2.73803670e-02,  -1.84549462e-02,\n",
       "         7.41256880e-02,  -3.94905154e-03,   7.25755918e-03,\n",
       "        -1.27648730e-03,  -1.05681264e-02,  -2.76083968e-01,\n",
       "         6.01506018e-02,  -3.86748428e-02,   7.15082769e-02,\n",
       "        -2.57821922e-02,   3.19832589e-02,   1.78317317e-02,\n",
       "        -7.50073251e-02,  -3.09825229e-01,   5.48963260e-03,\n",
       "        -3.35212368e-02,   5.65164359e-02,   3.06642316e-02,\n",
       "         1.00277586e-01,  -4.56287876e-02,  -1.28200558e-01,\n",
       "         6.36855707e-03,  -1.14870431e-01,  -4.13383332e-01,\n",
       "        -3.65919363e-01,   0.00000000e+00,   8.90327574e-02,\n",
       "         2.21537094e-02,   2.62806594e-01,   1.30410554e-01,\n",
       "        -6.12307165e-02,  -3.75092355e-01,   6.93677515e-02,\n",
       "        -1.96650651e-02,   3.60606102e-02,  -2.60155584e-01,\n",
       "         3.81137675e-02,   1.12884711e-01,  -4.52074308e-03,\n",
       "        -2.62722529e-01,  -4.42729649e-01,   9.32184633e-02,\n",
       "         2.19981610e-02,   5.23695899e-01,   5.82751989e-03,\n",
       "        -2.83305551e-02,  -2.58585474e-01,  -6.91720413e-02,\n",
       "         4.02736044e-02])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#смотрим коэффициенты, видим, что для некоторых признаков они равны нулю\n",
    "coeffs = clf.coef_\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20253190381202768, 0.18935903128990939)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удалим их и обучим исходный классификатор\n",
    "data_all_filt = data_all[:,coeffs > 10e-8]\n",
    "clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "scores = cross_val_score(clf, data_all_filt, target, cv=3, scoring = 'f1')\n",
    "filt_score = scores.mean()\n",
    "basic_score, filt_score\n",
    "#видим, что удаление признаков с нулевыми коэффициентами ухудшило модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20253190381202768, 0.18935903128990939, 0.19517231408808025)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#при построении исходной модели мы удаляли числовые признаки содержащие большое количество NaN-значений, попробуем удалить только\n",
    "#те числовые признаки, в которых ВСЕ значения NaN\n",
    "\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, в которых ВСЕ значения NaN\n",
    "threshold = 0.9999\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "\n",
    "scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "NaN_filtTestScore = scores.mean()\n",
    "\n",
    "basic_score, filt_score, NaN_filtTestScore\n",
    "#видим, что редакцией признаков модель улучшить не получилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34000, 220)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загругим и обработаем дынные наилучшим способом\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tol': (0.1, 0.0001, 1e-08), 'alpha': [0.5, 0.01, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выполним подбор параметров\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#max_iter=1000, alpha=0.01 - использовались ранее\n",
    "parameters = {'tol':(0.1, 0.0001, 0.00000001), 'alpha':[0.5, 0.01, 0.001]}\n",
    "clf = SGDClassifier(loss = 'log',max_iter = 1000, class_weight='balanced', random_state=42)\n",
    "grSch = GridSearchCV(clf, parameters, cv=3,scoring = 'f1')\n",
    "grSch.fit(data_all, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.07519515,  0.08626302,  0.08040365,  0.0859375 ,  0.12792977,\n",
       "         0.12695312,  0.10644531,  0.16210953,  0.1660157 ]),\n",
       " 'mean_score_time': array([ 0.0065105 ,  0.00651042,  0.0065105 ,  0.00585938,  0.00585938,\n",
       "         0.01106763,  0.0058593 ,  0.00651034,  0.0078125 ]),\n",
       " 'mean_test_score': array([ 0.189421  ,  0.19262216,  0.19262216,  0.19458108,  0.20253136,\n",
       "         0.20253136,  0.19371563,  0.19267047,  0.19267047]),\n",
       " 'mean_train_score': array([ 0.19268793,  0.19506552,  0.19506552,  0.2001414 ,  0.21130028,\n",
       "         0.21130028,  0.19628207,  0.20084792,  0.20084792]),\n",
       " 'param_alpha': masked_array(data = [0.5 0.5 0.5 0.01 0.01 0.01 0.001 0.001 0.001],\n",
       "              mask = [False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_tol': masked_array(data = [0.1 0.0001 1e-08 0.1 0.0001 1e-08 0.1 0.0001 1e-08],\n",
       "              mask = [False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'alpha': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.5, 'tol': 1e-08},\n",
       "  {'alpha': 0.01, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'tol': 1e-08},\n",
       "  {'alpha': 0.001, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'tol': 1e-08}],\n",
       " 'rank_test_score': array([9, 7, 7, 3, 1, 1, 4, 5, 5]),\n",
       " 'split0_test_score': array([ 0.18239661,  0.18239661,  0.18239661,  0.18115723,  0.19951446,\n",
       "         0.19951446,  0.18688772,  0.18375242,  0.18375242]),\n",
       " 'split0_train_score': array([ 0.19912127,  0.19912127,  0.19912127,  0.19050499,  0.21652422,\n",
       "         0.21652422,  0.1940544 ,  0.20775194,  0.20775194]),\n",
       " 'split1_test_score': array([ 0.1916955 ,  0.19397502,  0.19397502,  0.19086974,  0.19636194,\n",
       "         0.19636194,  0.19043382,  0.19043382,  0.19043382]),\n",
       " 'split1_train_score': array([ 0.19456193,  0.19680803,  0.19680803,  0.20495253,  0.21240995,\n",
       "         0.21240995,  0.19957442,  0.19957442,  0.19957442]),\n",
       " 'split2_test_score': array([ 0.19417173,  0.20149643,  0.20149643,  0.21171932,  0.21171932,\n",
       "         0.21171932,  0.20382713,  0.20382713,  0.20382713]),\n",
       " 'split2_train_score': array([ 0.1843806 ,  0.18926727,  0.18926727,  0.20496669,  0.20496669,\n",
       "         0.20496669,  0.19521739,  0.19521739,  0.19521739]),\n",
       " 'std_fit_time': array([  1.12391596e-07,   7.40872831e-03,   9.34420579e-03,\n",
       "          2.10961611e-03,   3.66784600e-02,   3.46919366e-02,\n",
       "          7.60624744e-03,   6.77144807e-02,   6.84570738e-02]),\n",
       " 'std_score_time': array([  4.60412183e-04,   4.60355977e-04,   9.20655764e-04,\n",
       "          7.97359942e-04,   1.94667955e-07,   6.68710712e-03,\n",
       "          1.12391596e-07,   4.60299792e-04,   1.59471988e-03]),\n",
       " 'std_test_score': array([ 0.00506904,  0.00785582,  0.00785582,  0.01274977,  0.00662256,\n",
       "         0.00662256,  0.00729439,  0.00834657,  0.00834657]),\n",
       " 'std_train_score': array([ 0.00616202,  0.00420734,  0.00420734,  0.00681398,  0.00478314,\n",
       "         0.00478314,  0.00237597,  0.00519584,  0.00519584])}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#смотрим результат, видим, что наилучшие параметры уже были использованны ранее\n",
    "grSch.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 43,  63,  85,  87, 120, 149, 159, 196], dtype=int64),)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Предлагаю судить о вкладе признаков по весам модели Lasso\n",
    "#смотрим индексы переменных с малым весом\n",
    "np.where(abs(coeffs) < 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 54,  90,  91,  94, 214], dtype=int64),)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#интересно, что все переменные с малым весам относятся к категориальным, преобразованным при помощи one-hot-encoding\n",
    "#каким исходным  признакам относятся эти признаки определись сложно\n",
    "#смотрим индексы переменных с большим весом\n",
    "np.where(abs(coeffs) > 0.5)\n",
    "#видим, что они относятся к числовым переменным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Var6', 'Var13', 'Var24')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#тогда зададимся вопросом, какие числовые признаки вносят наибольший и наименьший вклад в модель\n",
    "#таким же способом можно видеть, что наименьший вклад вносят признаки с индексами 0, 2, 5\n",
    "#наибольший - 3, 4, 14, 28, 36, 41, посмотрим, какие признаки отвечают этим индексам\n",
    "numVarsToStay[0],numVarsToStay[2],numVarsToStay[5]\n",
    "#наименьший вклад вносят "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Var21', 'Var22', 'Var73', 'Var126', 'Var153', 'Var189')"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numVarsToStay[3],numVarsToStay[4],numVarsToStay[14], numVarsToStay[28], numVarsToStay[36], numVarsToStay[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:179: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var184</th>\n",
       "      <th>Var185</th>\n",
       "      <th>Var186</th>\n",
       "      <th>Var187</th>\n",
       "      <th>Var188</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var190</th>\n",
       "      <th>Var209</th>\n",
       "      <th>Var230</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1248.158804</td>\n",
       "      <td>3.549648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.807407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var1  Var2  Var3  Var4  Var5         Var6       Var7  Var8  Var9  \\\n",
       "count   0.0   0.0   0.0   0.0   0.0    15.000000  15.000000   0.0   0.0   \n",
       "mean    NaN   NaN   NaN   NaN   NaN   593.600000   2.800000   NaN   NaN   \n",
       "std     NaN   NaN   NaN   NaN   NaN  1248.158804   3.549648   NaN   NaN   \n",
       "min     NaN   NaN   NaN   NaN   NaN     0.000000   0.000000   NaN   NaN   \n",
       "25%     NaN   NaN   NaN   NaN   NaN    73.500000   0.000000   NaN   NaN   \n",
       "50%     NaN   NaN   NaN   NaN   NaN   322.000000   0.000000   NaN   NaN   \n",
       "75%     NaN   NaN   NaN   NaN   NaN   472.500000   7.000000   NaN   NaN   \n",
       "max     NaN   NaN   NaN   NaN   NaN  5033.000000   7.000000   NaN   NaN   \n",
       "\n",
       "       Var10    ...      Var184  Var185  Var186  Var187  Var188      Var189  \\\n",
       "count    0.0    ...         0.0     0.0     0.0     0.0     0.0   13.000000   \n",
       "mean     NaN    ...         NaN     NaN     NaN     NaN     NaN  174.000000   \n",
       "std      NaN    ...         NaN     NaN     NaN     NaN     NaN   64.807407   \n",
       "min      NaN    ...         NaN     NaN     NaN     NaN     NaN  126.000000   \n",
       "25%      NaN    ...         NaN     NaN     NaN     NaN     NaN  144.000000   \n",
       "50%      NaN    ...         NaN     NaN     NaN     NaN     NaN  150.000000   \n",
       "75%      NaN    ...         NaN     NaN     NaN     NaN     NaN  192.000000   \n",
       "max      NaN    ...         NaN     NaN     NaN     NaN     NaN  372.000000   \n",
       "\n",
       "       Var190  Var209  Var230     labels  \n",
       "count     0.0     0.0     0.0  15.000000  \n",
       "mean      NaN     NaN     NaN   0.066667  \n",
       "std       NaN     NaN     NaN   0.258199  \n",
       "min       NaN     NaN     NaN   0.000000  \n",
       "25%       NaN     NaN     NaN   0.000000  \n",
       "50%       NaN     NaN     NaN   0.000000  \n",
       "75%       NaN     NaN     NaN   0.000000  \n",
       "max       NaN     NaN     NaN   1.000000  \n",
       "\n",
       "[8 rows x 193 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#перед запуском в этом пункте сначала запустить пункт 9\n",
    "#выполним этот пункт на тестовой выборке\n",
    "\n",
    "test_pred_proba = clf.predict_proba(test_all)[:,1]\n",
    "test_pred = clf.predict(test_all)\n",
    "#найдем объекты, на которых модель ошибается\n",
    "mistakeIndex = (target_test != test_pred)\n",
    "errorMeasure = np.abs(test_pred_proba - 0.5)\n",
    "errorAr = pd.DataFrame(np.vstack((mistakeIndex, errorMeasure)).T)\n",
    "#найдем объекты на которых при ошибке, большая вероятность\n",
    "erInd = errorAr[(errorAr.iloc[:,1] > 0.35) *(errorAr.iloc[:,0] == True)].index\n",
    "#отобразим статистику по этим объектам\n",
    "test.iloc[erInd,:].head(erInd.shape[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var184</th>\n",
       "      <th>Var185</th>\n",
       "      <th>Var186</th>\n",
       "      <th>Var187</th>\n",
       "      <th>Var188</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var190</th>\n",
       "      <th>Var209</th>\n",
       "      <th>Var230</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893.523019</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.734062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>640.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4053.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var1  Var2  Var3  Var4  Var5         Var6       Var7  Var8  Var9  \\\n",
       "count   0.0   0.0   0.0   1.0   0.0    14.000000  14.000000   0.0   0.0   \n",
       "mean    NaN   NaN   NaN   0.0   NaN  1008.000000   6.000000   NaN   NaN   \n",
       "std     NaN   NaN   NaN   NaN   NaN   893.523019   3.741657   NaN   NaN   \n",
       "min     NaN   NaN   NaN   0.0   NaN   469.000000   0.000000   NaN   NaN   \n",
       "25%     NaN   NaN   NaN   0.0   NaN   640.500000   7.000000   NaN   NaN   \n",
       "50%     NaN   NaN   NaN   0.0   NaN   756.000000   7.000000   NaN   NaN   \n",
       "75%     NaN   NaN   NaN   0.0   NaN   959.000000   7.000000   NaN   NaN   \n",
       "max     NaN   NaN   NaN   0.0   NaN  4053.000000  14.000000   NaN   NaN   \n",
       "\n",
       "       Var10    ...      Var184  Var185  Var186  Var187  Var188      Var189  \\\n",
       "count    0.0    ...         0.0     0.0     0.0     0.0     0.0    8.000000   \n",
       "mean     NaN    ...         NaN     NaN     NaN     NaN     NaN  300.000000   \n",
       "std      NaN    ...         NaN     NaN     NaN     NaN     NaN   55.734062   \n",
       "min      NaN    ...         NaN     NaN     NaN     NaN     NaN  198.000000   \n",
       "25%      NaN    ...         NaN     NaN     NaN     NaN     NaN  273.000000   \n",
       "50%      NaN    ...         NaN     NaN     NaN     NaN     NaN  309.000000   \n",
       "75%      NaN    ...         NaN     NaN     NaN     NaN     NaN  324.000000   \n",
       "max      NaN    ...         NaN     NaN     NaN     NaN     NaN  384.000000   \n",
       "\n",
       "       Var190  Var209  Var230     labels  \n",
       "count     0.0     0.0     0.0  15.000000  \n",
       "mean      NaN     NaN     NaN   0.200000  \n",
       "std       NaN     NaN     NaN   0.414039  \n",
       "min       NaN     NaN     NaN   0.000000  \n",
       "25%       NaN     NaN     NaN   0.000000  \n",
       "50%       NaN     NaN     NaN   0.000000  \n",
       "75%       NaN     NaN     NaN   0.000000  \n",
       "max       NaN     NaN     NaN   1.000000  \n",
       "\n",
       "[8 rows x 193 columns]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сравним ее со статистикой по случайным объектам\n",
    "data.head(erInd.shape[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#можно сделать вывод, что модель чаще с увереностью дает ложноотрицательные результаты, то есть не определяет, что объект\n",
    "#сконен к оттоку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#По итогам экспериметнов строим модель,выполняя стандартизацию числовых признаов, преобразуя категориальные признаки\n",
    "# c небольшим количеством категорий при помощи one-hot-encoding, удаляем признаки, в которых много NaN значений,\n",
    "#используем модель SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "\n",
    "data = pd.read_csv('orange_small_churn_data.csv', delimiter =',')\n",
    "data['labels'] = pd.read_csv('orange_small_churn_labels.csv', header=None)\n",
    "#конвертируем колонку labels в int\n",
    "data = data.astype({'labels': 'int32'})\n",
    "#заменим все -1 в целевой переменной на 0\n",
    "data['labels'] = data['labels'].map({1: 1, -1: 0})\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "target_test = np.array(test.iloc[:,-1])\n",
    "#подготовим даные:\n",
    "#выделим категориальные признаки (для baseline решения, возможно будет достаточно числовых)\n",
    "numericalVarCount = 190\n",
    "categorialVarCount = 40\n",
    "\n",
    "data_num = data.iloc[:, 0:numericalVarCount]\n",
    "#удалим числовые признаки, содержащие слишком большое количество NaN - значений\n",
    "threshold = 0.7\n",
    "NaN_frac = data_num.isna().sum(axis = 0)/data_num.shape[0]\n",
    "numVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_num = data_num.loc[:,numVarsToStay]\n",
    "#Перед построением моделей, подготовим данные: заменим NaN на медианные значения,\n",
    "medians = data_num.median()\n",
    "data_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию числовых признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data_num)\n",
    "\n",
    "# #обработаем категориальные признаки методикой one-hot-encoding\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "data_cat = data.iloc[:, numericalVarCount:-1]\n",
    "\n",
    "data_cat_oh = pd.get_dummies(data_cat, dummy_na=True, drop_first=True)\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_cat.shape[0]\n",
    "NaN_frac\n",
    "threshold = 0.1\n",
    "NaN_frac = data_cat.isna().sum(axis = 0)/data_num.shape[0]\n",
    "catVarsToStay = list(NaN_frac[NaN_frac < threshold].index)\n",
    "data_cat = data_cat.loc[:,catVarsToStay]\n",
    "data_cat = data_cat.fillna('NA').astype(str)\n",
    "\n",
    "#Подсчитаем количество уникальных значений в категориальных признаках, от этого будет зависеть способ кодировки\n",
    "unique_counts = []\n",
    "for c in data_cat.columns:\n",
    "    unique_counts.append(data_cat[c].dropna().unique().shape[0])\n",
    "cat_unique = pd.DataFrame()\n",
    "cat_unique['unique_counts'] = unique_counts\n",
    "cat_unique.index = data_cat.columns\n",
    "cat_unique.sort_values(by='unique_counts', ascending=False)\n",
    "cat_unique\n",
    "\n",
    "cat_feat_for_OHE = list(cat_unique[cat_unique['unique_counts'] < 50].index)\n",
    "cat_feat_for_OHE\n",
    "encoder = DV(sparse = False)\n",
    "data_cat_oh = encoder.fit_transform(data_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "\n",
    "data_all = np.hstack((data_num,data_cat_oh))\n",
    "data_all.shape\n",
    "\n",
    "#выполняем на ней ту же обработку, что для набора обучения\n",
    "test_num = test.iloc[:, 0:numericalVarCount]\n",
    "#выкинем признаки, которые выкидывали при обучении\n",
    "test_num = test.loc[:,numVarsToStay]\n",
    "#заполним NaN медианными значениями train!!! набора\n",
    "test_num.fillna(medians, inplace=True)\n",
    "#выполним стандартизацию, с теми же параметрами, что при обучении:\n",
    "test_num = scaler.transform(test_num)\n",
    "test_cat = test.iloc[:, numericalVarCount:-1]\n",
    "test_cat = test_cat.loc[:,catVarsToStay]\n",
    "test_cat = test_cat.fillna('NA').astype(str)\n",
    "test_cat_oh = encoder.transform(test_cat[cat_feat_for_OHE].T.to_dict().values())\n",
    "test_all = np.hstack((test_num,test_cat_oh))\n",
    "clf = SGDClassifier(loss = 'log', class_weight='balanced', max_iter=1000, tol=1e-4, alpha=0.01, random_state=42)\n",
    "clf.fit(data_all, target)\n",
    "scores = cross_val_score(clf, data_all, target, cv=3, scoring = 'f1')\n",
    "last_score = scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Как видно из анализа в пункте 1 модель можно улучшить посредством использования бОльшего количества данных"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
